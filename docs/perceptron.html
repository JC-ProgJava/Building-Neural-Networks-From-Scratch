<!doctype html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="Description" content="Building neural networks from scratch using Java.">
    <!-- Yandex.Metrika counter -->
<script type="text/javascript" >
   (function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};
   m[i].l=1*new Date();k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
   (window, document, "script", "https://mc.yandex.ru/metrika/tag.js", "ym");

   ym(79958107, "init", {
        clickmap:true,
        trackLinks:true,
        accurateTrackBounce:true
   });
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/79958107" style="position:absolute; left:-9999px;" alt="" /></div></noscript>
<!-- /Yandex.Metrika counter -->

    <title>The Perceptron</title>

    <!-- Math -->
    <link rel="stylesheet" href="katex/katex.min.css">
    <script defer src="katex/katex.min.js"></script>
    <script defer src="katex/auto-render.min.js"></script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body, {
            });
        });
    </script>

    <link rel="stylesheet" href="book.css" type="text/css">
    <link rel="stylesheet" href="print.css" type="text/css" media="print">
    <script src="darkMode.js"></script>
    <link rel="stylesheet" href="form.css" type="text/css">
    <script src="form.js"></script>
</head>
<body>
    <nav>
        <a href="index.html">
            <h1>Building Neural Networks from Scratch</h1>
        </a>
        <div id="dark-mode-container">
            <button onclick="toggleDarkMode();"></button>
        </div>
    </nav>
    <form name="rate" class="rating" method="post" netlify>
        <p class="label-form">Rate this book!</p>
        <label type="submit" onclick="hide();">
          <input type="radio" name="stars" value="1" />
          <span class="icon">★</span>
        </label>
        <label type="submit" onclick="hide();">
          <input type="radio" name="stars" value="2" />
          <span class="icon">★</span>
          <span class="icon">★</span>
        </label>
        <label type="submit" onclick="hide();">
          <input type="radio" name="stars" value="3" />
          <span class="icon">★</span>
          <span class="icon">★</span>
          <span class="icon">★</span>
        </label>
        <label type="submit" onclick="hide();">
          <input type="radio" name="stars" value="4" />
          <span class="icon">★</span>
          <span class="icon">★</span>
          <span class="icon">★</span>
          <span class="icon">★</span>
        </label>
        <label type="submit" onclick="hide();">
          <input type="radio" name="stars" value="5" />
          <span class="icon">★</span>
          <span class="icon">★</span>
          <span class="icon">★</span>
          <span class="icon">★</span>
          <span class="icon">★</span>
        </label>
    </form>
    <div id="visible">
        <h2>Chapter 2 - The Perceptron</h2>
        <h4 class="quote">“I think the brain is essentially a computer and consciousness
            is like a computer program. It will cease to run when the computer is turned
            off. Theoretically, it could be re-created on a neural network, but that would
            be very difficult, as it would require all one's memories.”<br>— Stephen Hawking</h4>
        <p>Now that we had an introduction, it is time to introduce a basic computational model
            called the perceptron, which is a model in a collection of models called <em>artificial
            neurons</em>, in general. The perceptron was invented by Frank Rosenblatt in 1958. Rosenblatt
            defined the perceptron as a unit of computation that had a threshold \(\Theta\), and received inputs
            \(i_1, i_2, ..., i_n\), which are multiplied by \(w_1, w_2, ..., w_n\) respectively. He then proposed that
            all of the products be summed together and another constant called the <em>bias</em> was added, for
            which the perceptron would output 1 if the sum was greater than or equal to the threshold,
            and 0 if it was smaller.</p>
        <p>In mathematical terms, \(t = \displaystyle\sum^{n}_{k\ =\ 1}{w_{k} i_{k}}\),</p>
        <p>output \(\left\{\begin{array}{l} 1,\ b + t > \Theta \\ 0,\ b + t ≤ \Theta \end{array} \right.\).
            In other words, a perceptron is a unit consisting of something called a <em>weight</em>, which was multiplied
            by the <em>input</em> (sometimes called the <em>activation</em>), and if the sum of the products of the two was bigger than a
            number called the threshold, the perceptron would output a 1, or 0 if not.</p>
        <p>Another way to think about this is, the threshold is a value for which classifies all events \(a\) as similar if the
            summation of the product of their inputs and a set of weights with another constant called the <em>bias</em> is higher
            than the threshold. This also could be thought of as an event with a point \((x,\ y)\). The threshold would therefore
            be a line \(y\ =\ \Theta\), which separated two different sets of points. Here is a graphical representation:</p>
        <img src="Images/perceptronGraph.png">
        <p class="caption">Figure 2-1: A graphical representation of a threshold separating two points</p>
        <p>Like the diagram, the perceptron can similarly “separate” two different inputs and classify or predict the output
            for that input. So, now that we have these two basic properties, we can start to understand why machine learning
            and artificial intelligence are important in the field of data science. For example, say you want to classify whether
            a 3 by 3 grid of inputs is a 0 or 1. This requires a method to separate different sets of inputs and identify common
            features. In the perceptron model, since the weights, biases, and threshold are the only unknown variables, these
            are the ones we need to figure out to have the desired classification result. Machine learning, therefore, can be
            defined as the method that achieves this task of finding ideal values for the weights, bias, and threshold. Do
            note that other models may not have a threshold, but require an <em>activation function</em> which we will discuss
            in later chapters.</p>
        <p>This was a ground-breaking invention that inspired others after Rosenblatt and caused the first AI winter. An AI
            winter is a period when no or little progress was made in the field of artificial intelligence. After the invention
            of the perceptron, professor Marvin Minsky in his book <em>Perceptrons</em> proved that a single layer of these perceptrons
            wasn’t able to predict anything. This led to a misunderstanding which resulted in a decrease in research on the area.
            Minsky actually also wrote in the same book that a network of several layers would have the ability to approximate
            any function, which resulted in the Universal Approximation Theorem, stating that a neural network with multiple layers
            could approximate any continuous (and predictable) function to any degree of accuracy.</p>
        <p>Given this information, neural networks are just a collection or array of these perceptrons(although they may have a
            different type of neuron instead), connected through multiple layers. Usually, the first layer is called the <em>input
            layer</em>, the middle layers are called the <em>hidden layers</em> and the last layer is called the <em>output layer</em>. Below is a diagram
            of a neural network.</p>
        <img style="width: 40%;" src="Images/neural-network.png">
        <p class="caption">Figure 2-2: Neural Network Architecture</p>
        <p>This network can be called a neural network with structure 3-4-2(appears in the layer order from left to right).
            The lines on the diagram show the different connections between neurons in the network, which are represented by
            orange circles. The connections can be referred to as weights, which (if you remember) are multiplied by the <em>input</em>
            or <em>activation</em>. It is important to note that there is only one bias in the weighted sum to each neuron in the next layer. Usually, there are no connections <em>towards</em> a bias, but biases are connected
            to the next layer’s neurons. Networks can be called “single-layered networks” when there are only two layers in it(input and output).
            We will talk more about neural networks in Chapter 4.</p>
        <h3 id="summary">Chapter Summary</h3>
        <ol>
            <li>A perceptron is a type of artificial neuron(I will be calling it a ‘neuron’ instead, throughout most of the book).</li><br>
            <li>The perceptron is a computational model consisting of <em>weights</em>, a set of <em>inputs</em> or <em>activations</em>, <em>biases</em>,
                and a <em>threshold</em>.</li><br>
            <li>The <em>input</em> to the perceptron is multiplied by the <em>weight</em> and a <em>bias</em> is added. If the result is bigger than another
                value the <em>threshold</em>, then the perceptron outputs a 1, otherwise, it outputs 0.</li><br>
            <li>The perceptron model was invented by Frank Rosenblatt in 1958.</li><br>
            <li><p>A perceptron in mathematical terms is: \(t = \displaystyle\sum^{n}_{k\ =\ 1}{w_{k} i_{k}}\),</p>
                <p>where the output of the perceptron
                is \(\left\{\begin{array}{l} 1,\ b + t > \Theta \\ 0,\ b + t ≤ \Theta \end{array} \right.\), where \(w_k\) and \(i_k\) are the weights and inputs at index \(k\) respectively.
                \(n\) is the total number of weights connected to the perceptron and \(\Theta\) is the threshold value. The output is also alternatively expressed as:
                \(\left\{\begin{array}{l} 1,\ b + t ≥ \Theta \\ 0,\ b + t < \Theta \end{array} \right.\), which rarely makes a difference to the overall output of the perceptron and the accuracy
                of the neural network.</p></li><br>
            <li>Machine learning is a set of algorithms that finds ideal values for the <em>weights</em>, <em>biases</em>, and <em>threshold</em>.</li><br>
            <li>A threshold is like a line that separates two different sets of labeled inputs.</li><br>
            <li>Marvin Minsky in his book <em>Perceptrons</em> proved that a layer of perceptrons could not predict anything, he also stated that multiple layers of perceptrons
                were able to approximate any function. This led to an AI winter.</li><br>
            <li>The Universal Approximation Theorem states that any continuous function can be approximated to any degree of accuracy using a multilayer neural network.</li><br>
            <li>An AI winter is a period when there is little or no further advancement in the field of Artificial Intelligence. This usually is caused by a lack of sponsoring or
                money that motivates the research in the field of AI.</li><br>
            <li>Perceptrons may not have a <em>threshold</em> or <em>bias</em>, but(in that case) will require an <em>activation function</em>(Chapter 3).</li><br>
            <li>A network consists of several layers of neurons. Single-layer networks have two layers, the first called the <em>input layer</em> and the last called the <em>output layer</em>.
                Multi-layer networks also have <em>hidden layers</em>, which are the layers in between the <em>input layer</em> and the <em>output layer</em>.</li>
        </ol>
        <br>
        <button onclick="location.href = 'intro.html';">Previous Chapter</button>
        <button onclick="location.href = 'activation.html';">Next Chapter</button>
    </div>
</body>
<script>
// Courtesy to https://www.w3schools.com/howto/howto_js_navbar_hide_scroll.asp BELOW
var prevScrollpos = window.pageYOffset;
window.onscroll = function() {
  var currentScrollPos = window.pageYOffset;
  if (prevScrollpos > currentScrollPos) {
    document.getElementsByTagName("nav")[0].style.top = "0";
  } else {
    document.getElementsByTagName("nav")[0].style.top = -document.getElementsByTagName("nav")[0].offsetHeight + "px";
  }
  prevScrollpos = currentScrollPos;
}
// Code borrowed, please look at the link for the tutorial to make collapsible sections
// Code was modified for suitability purposes
// END W3SCHOOL CODE
</script>
</html>
